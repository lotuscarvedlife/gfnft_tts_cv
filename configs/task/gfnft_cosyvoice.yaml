name: "GFNFT-COSYVOICE"

data:
  path: "data/lm_input_tensor/"
  train_size: 0.95
  limit_prompts: 1000

model:
  name: "cosyvoice"
  model_dir: "pretrained_models/CosyVoice2-0.5B"
  lora_config:
    _target_: peft.LoraConfig   # 指定使用的类
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "up_proj", "down_proj"]  # 选择需要微调的关键层，包括注意力机制关键层、投影层和全连接层
    r: 64                       # 低秩矩阵的秩
    lora_alpha: 16              # 缩放因子
    lora_dropout: 0.1           # LoRA层中的dropout概率
    bias: "none"                # 不使用偏置，即不对偏置项进行微调
    fan_in_fan_out: True        # 应该和初始化有关

training:
  subtb_lambda: 1.0
  pf_temp_high: 2.0
  pf_temp_low: 0.5
  pf_temp_prob: 0.666
  use_buffer_prob: 0.25
  n_samples: 10
  lr: 0.0001
  accumulate_grad_batches: 2
  epochs: 100
  use_4bit: False

eval:
  n_probes: 10    # 探针采样的数量
  diversity_metric: "sequence_embedding"

reward:
  temp_start: 1.0     # 初始温度参数
  temp_end: 0.8       # 最终温度参数
  temp_horizon: 750   # 温度变化的时间范围，即在前750步骤内温度将从初始温度线性降低至最终温度为0.8。
  vocab_alpha: -50
  sentence_validator: null
  buffer_size: 50     # 经验回放缓冲区的大小，可以存储50对样本和对应的奖励

callbacks:
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/logP(s) (avg)"
    mode: "max"
    save_last: True
    dirpath: ${save_dir}/checkpoints/${now:%Y-%m-%d}_${now:%H-%M-%S}
    filename: "epoch={epoch:03d}"
    auto_insert_metric_name: True
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    every_n_epochs: 25
    dirpath: ${save_dir}/checkpoints/periodic/${now:%Y-%m-%d}_${now:%H-%M-%S}
    filename: "epoch_{epoch:03d}_periodic"
    save_top_k: -1
    save_weights_only: True
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val/logP(s) (avg)"
    mode: "max"
    patience: 50

constraints:
  min_sentence_len: 1
  max_sentence_len: 160
  illegal_tokens: [
    "<|endoftext|>",
    "\n", "\n\n", "\t", "\"", "\"\"", "\"\"\"",
    "http", "https", "://", "www", 
    "Â", "\"?", "?\"",
    "$$", "$$$$",
    "@@", "@@@@", "@@@@@@@@",
    "##", "###", "####", "########", "################", "################################",
    "%%", "%%%%",
    "^", "^^", "^^^^",
    "&&",
    "|", "||", "||||",
    "~", "~~", "~~~~", "~~~~~~~~", "~~~~~~~~~~~~~~~~",
    "!", "!!", "!!!", "!!!!", "!!!!!", "!!!!!!!!",
    "?", "??", '???', "????", "?????", "????????",
    "..", "...", "....", ".....", "......", ".......", "........", ".........", ".............", "................", "..................", "........................", "................................", "................................................................",
    "**", "***", "****", "*****", "********", "************", "****************", "********************************",
    "--", "---", "----", "-----", "------", "-------", "--------", "---------", "----------", "-----------", "------------", "-------------", "--------------", "---------------", "----------------", "--------------------", "------------------------", "--------------------------------", "------------------------------------------------", "--------------------------------------------------------", "----------------------------------------------------------------",
    "==", "===", "====", "======", "========", "============", "================", "================================", "================================================================",
    "__", "___", "____", "_____", "______", "_______", "________", "________________", "________________________", "________________________________", "________________________________________________________________",
    # Abbreviations that have periods in them
    "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", 
    "US", "Mr", "Mrs", "M", "Ms", "Dr", "Prof", "Jr", "St", "Av",
  ]
